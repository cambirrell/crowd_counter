{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crowd Counter Model\n",
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, Lambda, ToTensor\n",
    "import warnings\n",
    "# Suppress the specific UserWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"The default value of the antialias parameter.*\", category=UserWarning)\n",
    "\n",
    "device = torch.device(\"cuda:10\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for the images (you can customize this based on your needs)\n",
    "test_size = (512,512)\n",
    "out_size = (64,64)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(test_size),\n",
    "])\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CrowdDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root='jhu_crowd_v2.0/', split='train', transform=None):\n",
    "        self.input_folder = os.path.join(root, split, 'images')\n",
    "        self.output_folder = os.path.join(root, split, 'den')\n",
    "        self.input_dataset = datasets.ImageFolder(self.input_folder, transform=transform)\n",
    "        self.classes = self.input_dataset.classes\n",
    "        self.indices = list(range(len(self.input_dataset)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load input image\n",
    "        input_data = self.input_dataset[self.indices[index]][0]  # [0] to get the data (image)\n",
    "\n",
    "        # Load output data from CSV file\n",
    "        image_name = os.path.basename(self.input_dataset.imgs[self.indices[index]][0])\n",
    "        csv_path = os.path.join(self.output_folder, f\"{image_name.replace('.jpg', '.csv')}\")\n",
    "        df = pd.read_csv(csv_path, header=None)\n",
    "        original_data = torch.tensor(df.values).float()\n",
    "        resized_tensor = F.interpolate(original_data.unsqueeze(0).unsqueeze(0), size=out_size, mode='bilinear', align_corners=False)\n",
    "        resized_tensor = resized_tensor.squeeze(0).squeeze(0)\n",
    "        output_data = resized_tensor * (original_data.sum() / resized_tensor.sum())\n",
    "        return {'input': input_data, 'output': output_data}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all the datasets\n",
    "train_dataset = CrowdDataset(split='train', transform=transform)\n",
    "val_dataset = CrowdDataset(split='val', transform=None)\n",
    "test_dataset = CrowdDataset(split='test', transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n",
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n",
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n",
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n",
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n",
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n",
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n",
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n",
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n",
      "torch.Size([8, 3, 512, 512]) torch.Size([8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "#loop throough first 10 batches\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(batch['input'].shape, batch['output'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrebBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(UrebBlock, self).__init__()\n",
    "        self.CB = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),  # Add padding to keep the spatial dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1),   # Add padding to keep the spatial dimensions\n",
    "        )\n",
    "        self.DR = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),  # Add padding to keep the spatial dimensions\n",
    "        )\n",
    "        self.CEB = nn.Sequential(\n",
    "            nn.Conv2d(33, 32, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1),  # Add padding to keep the spatial dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),   # Add padding to keep the spatial dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 1, kernel_size=3, padding=1),   # Add padding to keep the spatial dimensions\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        r = self.CB(x)\n",
    "        cm = self.CEB(torch.cat((r, self.DR(x)), dim=1))\n",
    "        return cm * r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGadjusted(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGadjusted, self).__init__()\n",
    "        self.vgg = models.vgg16(pretrained=True).features\n",
    "        self.C3 = self.vgg[:17]\n",
    "        self.C4 = self.vgg[17:24]\n",
    "        self.C5 = self.vgg[24:]\n",
    "        self.C6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 32, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),  # Add padding to keep the spatial dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1),   # Add padding to keep the spatial dimensions\n",
    "            nn.Upsample(size=(16, 16), mode='bilinear', align_corners=False)\n",
    "        )\n",
    "        self.ureb3 = UrebBlock(256)\n",
    "        self.ureb4 = UrebBlock(512)\n",
    "        self.ureb5 = UrebBlock(512)\n",
    "\n",
    "        self.y5_upsample = nn.Upsample(size=(32, 32), mode='bilinear', align_corners=False)\n",
    "        self.y4_upsample = nn.Upsample(size=(64, 64), mode='bilinear', align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c3 = self.C3(x)\n",
    "        r3 = self.ureb3(c3)\n",
    "        c4 = self.C4(c3)\n",
    "        r4 = self.ureb4(c4)\n",
    "        c5 = self.C5(c4)\n",
    "        r5 = self.ureb5(c5)\n",
    "        y6 = self.C6(c5)\n",
    "        y5 = y6 + r5\n",
    "        y4 = self.y5_upsample(y5) + r4\n",
    "        y3 = self.y4_upsample(y4) + r3\n",
    "        out = {'y3': y3, 'y4': y4, 'y5': y5, 'y6': y6, 'cm3': r3, 'cm4': r4, 'cm5': r5, }\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "        self.lambda_c = 0.1\n",
    "        self.cm_keys = ['cm3', 'cm4', 'cm5']\n",
    "        self.y_keys = ['y3', 'y4', 'y5']\n",
    "\n",
    "    def _scale_regularize_tensor(self, tensor, out_size):\n",
    "        # print(tensor.shape)\n",
    "        # print(tuple(list(out_size)[1:]))\n",
    "        out_size = tuple(list(out_size)[1:])\n",
    "        # print(tensor.unsqueeze(0).shape)\n",
    "        resized = F.interpolate(tensor.unsqueeze(0), size=out_size, mode='bilinear', align_corners=False)\n",
    "        resized = resized.squeeze(0).squeeze(0)\n",
    "        scaled_tensor = resized * (tensor.sum() / resized.sum())\n",
    "        return scaled_tensor\n",
    "\n",
    "    def forward(self, y_hat, y):\n",
    "        loss_C = sum(torch.log(y_hat[cm_key]).sum() for cm_key in self.cm_keys)\n",
    "        loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
    "        return loss_C + self.lambda_c * loss_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "model = VGGadjusted().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = LossFunction()\n",
    "epochs = 1\n",
    "loop = tqdm(total=len(train_dataloader)*epochs, position=0, leave=False)\n",
    "val_loss = []\n",
    "train_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   0%|          | 1/284 [00:03<15:12,  3.23s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   1%|          | 2/284 [00:05<11:27,  2.44s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   1%|          | 3/284 [00:06<08:41,  1.86s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   1%|▏         | 4/284 [00:07<07:36,  1.63s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   2%|▏         | 5/284 [00:09<07:27,  1.60s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   2%|▏         | 6/284 [00:10<07:25,  1.60s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   2%|▏         | 7/284 [00:13<09:29,  2.06s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   3%|▎         | 8/284 [00:15<08:32,  1.86s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   3%|▎         | 9/284 [00:16<07:40,  1.68s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   4%|▎         | 10/284 [00:17<07:24,  1.62s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   4%|▍         | 11/284 [00:19<07:25,  1.63s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   4%|▍         | 12/284 [00:21<07:22,  1.63s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   5%|▍         | 13/284 [00:22<06:34,  1.46s/it, loss=nan]/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 64, 64])) that is different to the input size (torch.Size([8, 1, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 32, 32])) that is different to the input size (torch.Size([8, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "/tmp/ipykernel_1503241/1075309005.py:20: UserWarning: Using a target size (torch.Size([8, 8, 16, 16])) that is different to the input size (torch.Size([8, 1, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_d = sum(F.mse_loss(y_hat[cm_key] * y_hat[y_key], y_hat[cm_key] * self._scale_regularize_tensor(y, y_hat[cm_key].squeeze(1).shape)) for y_key, cm_key in list(zip(self.y_keys, self.cm_keys)))\n",
      "Epoch [0/1]:   5%|▍         | 14/284 [00:23<05:56,  1.32s/it, loss=nan]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(checkpoint, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     loop\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 10\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     11\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m         input_data \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m, in \u001b[0;36mCrowdDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m image_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dataset\u001b[38;5;241m.\u001b[39mimgs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[index]][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     25\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m original_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(df\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     28\u001b[0m resized_tensor \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(original_data\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), size\u001b[38;5;241m=\u001b[39mout_size, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py:236\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py:389\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    387\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m union_categoricals(arrs, sort_categories\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_cat_dtypes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m result[name]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    391\u001b[0m         warning_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(name))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/concat.py:117\u001b[0m, in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     target_dtype \u001b[38;5;241m=\u001b[39m np_find_common_type(\u001b[38;5;241m*\u001b[39mdtypes)\n\u001b[0;32m--> 117\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kinds \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# GH#39817 cast to object instead of casting bools to numeric\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def training():\n",
    "    model.train()\n",
    "    checkpoint = {\n",
    "        'epoch': 0,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': 0.0,\n",
    "    }\n",
    "    for epoch in range(epochs):\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input_data = batch['input'].to(device)\n",
    "            output_data = batch['output'].to(device)\n",
    "            output_pred = model(input_data)\n",
    "            loss = criterion(output_pred, output_data)\n",
    "            loss.backward()\n",
    "            if i % 100 == 0:\n",
    "                train_loss.append(loss.item())\n",
    "                # val_loss.append()\n",
    "            optimizer.step()\n",
    "            loop.set_description(f\"Epoch [{epoch}/{epochs}]\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            loop.update(1)\n",
    "        checkpoint['epoch'] = epoch\n",
    "        checkpoint['model_state_dict'] = model.state_dict()\n",
    "        checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        checkpoint['loss'] = loss.item()\n",
    "        torch.save(checkpoint, f'checkpoint_{epoch}.pth')\n",
    "    loop.close()\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot val loss\n",
    "plt.plot(val_loss)\n",
    "#plot train loss\n",
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
